#!/usr/bin/env bash

# 5.1 Synthetic Experiments (Exploring Problem Dimension)

# Command line for experiment with job_id=AES-128, PermK Compressor, d=1K
python run.py --rounds "20000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9117" --group-name "0.007 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "aes_11_current_0.007_launch_5_zz" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__,aes:1" --logfile "../logs/zz_1_log_1683248318.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "4aes_1k_d_dgd[fp64]permk.bin" --out "AES-128, PermK Compressor, d=1K.bin"

# Command line for experiment with job_id=PermK Compressor, d=1K
python run.py --rounds "20000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9117" --group-name "0.007 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "current_0.007_launch_5_zzz" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248318.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "4_1k_d_dgd[fp64]permk.bin" --out "PermK Compressor, d=1K.bin"

# Command line for experiment with job_id=Identity Compressor, d=1K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "11_job_id_1683166184_zzz" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx" --logfile "../logs/11_log_1683166184.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "1_1k_d_dgd[fp64].bin" --out "Identity Compressor, d=1K.bin"

# Command line for experiment with job_id=AES-128, Identity Compressor, d=1K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "16_job_id_1683174351_zzz" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx,aes:1" --logfile "../logs/16_log_1683174351.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "2_1k_d_dgd[fp64]aes-128.bin" --out "AES-128, Identity Compressor, d=1K.bin"

# Command line for experiment with job_id=HE/CKKS, Identity Compressor, d=1K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "17_job_id_1683176514_zzz" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx,he:1" --logfile "../logs/17_log_1683176514.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "3_1k_d_dgd[fp64]ckks.bin" --out "HE/CKKS, Identity Compressor, d=1K.bin"

# Command line for experiment with job_id=AES-128, PermK Compressor, d=10K
python run.py --rounds "20000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:10000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9117" --group-name "0.007 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "aes_22_current_0.007_launch_5_zz" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__,aes:1" --logfile "../logs/zz_1_log_1683248318.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "8aes_10k_d_dgd[fp64]permk.bin" --out "AES-128, PermK Compressor, d=10K.bin"

# Command line for experiment with job_id=PermK Compressor, d=10K
python run.py --rounds "20000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:10000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9117" --group-name "0.007 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "current_0.007_launch_5_zz_1683461238" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248318.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "8_10k_d_dgd[fp64]permk.bin" --out "PermK Compressor, d=10K.bin"

# Command line for experiment with job_id=Identity Compressor, d=10K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:10000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "11_job_id_1683166184_zzz_1683440926" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx" --logfile "../logs/11_log_1683166184.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "5_10k_d_dgd[fp64].bin" --out "Identity Compressor, d=10K.bin"

# Command line for experiment with job_id=AES-128, Identity Compressor, d=10K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:10000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "16_job_id_1683174351_zzz_1683442442" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx,aes:1" --logfile "../logs/16_log_1683174351.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "6_10k_d_dgd[fp64]aes-128.bin" --out "AES-128, Identity Compressor, d=10K.bin"

# Command line for experiment with job_id=HE/CKKS, Identity Compressor, d=10K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:10000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "17_job_id_1683176514_zzz_1683449137" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx,he:1" --logfile "../logs/17_log_1683176514.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "7_10k_d_dgd[fp64]ckks.bin" --out "HE/CKKS, Identity Compressor, d=10K.bin"

# Command line for experiment with job_id=AES-128, PermK Compressor, d=100K
python run.py --rounds "20000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:100000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9117" --group-name "0.007 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "aes_33_current_0.007_launch_5_zz" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__,aes:1" --logfile "../logs/z__1_log_1683248318.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "12aes_100k_d_dgd[fp64]permk.bin" --out "AES-128, PermK Compressor, d=100K.bin"

# Command line for experiment with job_id=PermK Compressor, d=100K
python run.py --rounds "20000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:100000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9117" --group-name "0.007 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "current_0.007_launch_5_zz_1683590845" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248318.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "12_100k_d_dgd[fp64]permk.bin" --out "PermK Compressor, d=100K.bin"

# Command line for experiment with job_id=Identity Compressor, d=100K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:100000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "11_job_id_1683166184_zz_1683472086" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx" --logfile "../logs/11_log_1683166184.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "9_100k_d_dgd[fp64].bin" --out "Identity Compressor, d=100K.bin"

# Command line for experiment with job_id=AES-128, Identity Compressor, d=100K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:100000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "16_job_id_1683174351_zz_1683476551" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx,aes:1" --logfile "../logs/16_log_1683174351.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "10_100k_d_dgd[fp64]aes-128.bin" --out "AES-128, Identity Compressor, d=100K.bin"

# Command line for experiment with job_id=HE/CKKS, Identity Compressor, d=100K
python run.py --rounds "3000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "1" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:100000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "0" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "456" --group-name "" --comment "" --hostname "kw60797" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "17_job_id_1683176514_zz_1683529789" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,stepsize_multiplier:1.0,th_stepsize_cvx,he:1" --logfile "../logs/17_log_1683176514.txt" --client-compressor "ident" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "fl_pytorch_simulation" --loglevel "debug" --logfilter ".*" --out "11_100k_d_dgd[fp64]ckks.bin" --out "HE/CKKS, Identity Compressor, d=100K.bin"
