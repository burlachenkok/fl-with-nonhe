#!/usr/bin/env bash

# 5.1 Synthetic Experiments (CASE 3)

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.00001" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "13552" --group-name "0.003 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "01_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248561.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.00001_launch_1.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.00003" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "13552" --group-name "0.003 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "02_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248561.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.00003_launch_2.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.00005" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "13552" --group-name "0.003 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "03_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248561.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.00005_launch_3.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.00007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9700" --group-name "0.005 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "04_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248554.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.00007_launch_4.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.0003" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "9117" --group-name "0.007 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "05_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248318.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.0003_launch_5.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.001" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "17274" --group-name "0.01 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "06_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248314.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.001_launch_6.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.003" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "17274" --group-name "0.01 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "07_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248314.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.003_launch_7.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.005" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "17274" --group-name "0.01 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "08_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248314.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.005_launch_8.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.007" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "17274" --group-name "0.01 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "09_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248314.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.007_launch_9.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.01" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "17274" --group-name "0.01 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "10_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248314.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.01_launch_10.bin"

python run.py --rounds "30000" --client-sampling-type "uniform" --num-clients-per-round "50" --global-lr "0.05" --global-optimiser "sgd" --global-weight-decay "0.0" --number-of-local-iters "1" --batch-size "24" --local-lr "1" --local-optimiser "sgd" --local-weight-decay "0.0" --dataset "generated_for_quadratic_minimization" --dataset-generation-spec "homogeneous:0,mu:1.0,l:10.0,samples_per_client:12,clients:50,variables:1000" --loss "mse" --model "linear" --metric "loss" --global-regulizer "none" --global-regulizer-alpha "0.0" --checkpoint-dir "../check_points" --do-not-save-eval-checkpoints --data-path "../data/" --compute-type "fp64" --gpu "-1" --num-workers-train "0" --num-workers-test "0" --deterministic --manual-init-seed "123" --manual-runtime-seed "17274" --group-name "0.01 group" --comment "" --eval-every "100" --eval-async-threads "0" --save-async-threads "0" --threadpool-for-local-opt "50" --run-id "11_{now}" --algorithm "dcgd" --algorithm-options "internal_sgd:full-gradient,__stepsize_multiplier__:1.0,___th_stepsize_cvx__" --logfile "../logs/1_log_1683248314.txt" --client-compressor "permk" --extra-track "full_gradient_norm_train,full_objective_value_train" --initialize-shifts-policy "zero" --wandb-key "" --wandb-project-name "" --loglevel "debug" --logfilter ".*" --out "current_0.05_launch_11.bin"

